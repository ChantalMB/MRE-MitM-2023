# The Digital Archive

DISCUSS: How the digital archive is being repurposed(?) as a source of Big Data (how it lends itself to this and likewise, how it does not), and by extension how the metadata associated with the digitized item and the metadata created when using the digitized item for machine learning purposes affects the final product.

In 2016, book historian Ryan Cordell called for more robust methods to describe digital artifacts bibliographically within the context of utilizing digitized archives. Research which makes use of these digital objects often fails to account for the sources, technologies, and social realities of the objects’ creation in ways that make their affordances and limitations more readily visible and available for critique.[@cordell_q_2017, 191] [@mak_archaeology_2014, 3] Likewise, in conceptualizing digital archives as sources of data in their book, *Data Feminism*, Catherine D'Ignazio and Laura Klein discuss data science and ethics as informed by intersectional feminism; they continuously emphasize the necessity of further context at all stages of working with "data", from acquisition to analysis, because the context which data is situated in is seen as essential to the ultimate "framing and communication of results" formed through its use.[@dignazio_data_2020, 164] 

When archival materials are integrated into research utilizing more traditional methods of historical inquiry, the subject being analyzed tends to be singular, which in turn makes answering these questions manageable without extensive organization, since there is cohesion across sources. Comparatively, the large amount of data needed for machine learning tasks often results in these questions being difficult to answer on a microscopic level, because the metadata for each archival item used is omitted during the process of data collection. The scale of the dataset produced makes such detailed information be perceived as unnecessary. Yet these details which go into the first step of building a machine learning model are vital to understanding the influences and limitations of it; the foundations which machines learn with and from are human, meaning that they contain "human subjectivities, biases, and distortions" like all other works created by humans.[@lee_compounded_2021] In order to produce meaningful output using either analog or automated research methods such as machine learning for identification, it is vital to interrogate the input that contributed to the making of the method being applied for answers regarding social, cultural, historical, institutional, and material conditions under which that input was produced, as well as about the identities of the people who created it.[@dignazio_data_2020, 152]

## As Big Data
- More robust methods to describe digital artifacts bibliographically within the context of utilizing digitized archives
- Research which makes use of these digital objects often fails to account for the sources, technologies, and social realities of the objects’ creation in ways that make their affordances and limitations more readily visible and available for critique.
- The context which data is situated in is seen as essential to the ultimate "framing and communication of results" formed through its use



- Digital collections are increasingly interrogated and explored for historical research. They have facilitated access and, as a result, become a critical platform where scholars find and select sources. The reliance on such digitized resources can be problematic, since, oftentimes, the underlying data remain opaque. As Yale points out, archives (both digital and analogue) are not just ‘sources of history … they are also its subjects, sites with histories and politics of their own’ (Yale, 2015).
- With digitization and full-text indexing, millions of pages are just a few keystrokes (or lines of code) away (Milligan, 2013).
- Answers to critical questions in this regard—‘why material was chosen and curated, how it was obtained, and from which specific source material it was transformed into a digital copy’—are hard to come by (Hauswedell et al., 2020).
- Digitization initiatives are necessarily highly selective.
- Many factors influence the selection of titles for digitization, including prior decisions about microfilm preservation (it is much more expensive to digitize from hard copy than from well-preserved microfilm), contemporary research interests, perceived quality, and copyright considerations (Fyfe, 2016; Hauswedell et al., 2020)
- But understanding missing data and gaps (what’s in and what’s out) is critical even for large collections and it requires new methods and strategies. Discussing the digitized British Library Newspapers, Brake asks ‘So what do we have?’ (emphasis in the original) reminding historians that a large majority of newspapers are still absent, which makes the digitized materials only ‘indicative, icebergs on a surface that constantly remind readers of the invisible dangers, and riches, in their immediate environs’ (Brake, 2012).
- Secondly, in countries such as Britain where digitization has been arranged on a commercial basis, only a very small fraction of the collection is freely accessible for scholarly research at scale --> researchers can pay to access more, yet that leaves the source of the data and thus their research opaque

- There is much to be gained by developing a checklist for researchers carrying out machine learning projects in the context of treating cultural heritage collections as data. Even with good intentions, such projects risk kitschifying or exploiting those represented in the digitized collections in question; glossing over digitization subtleties that impact the performance and output of machine learning models; utilizing machine learning when it is not necessary due to organizational agendas surrounding emerging technologies; beginning machine learning projects with no plans for sustainability; or violating the privacy of end-users of systems that are built.
- Indeed, from a scientific standpoint, incomplete documentation of a dataset or model can lead to unintentional misuse by other researchers; insufficient evaluation of a dataset or model can lead to unforeseen issues of generalization when operationalized; and lack of clarity surrounding copyright can hinder the adoption of a dataset or model. From an ethical standpoint, machine learning datasets risk exploiting personal data and raising questions of privacy; labor practices behind data annotations are not always foregrounded, leading to questions of labor exploitation; machine learning models can perpetuate marginalization and oppression; and operationalized systems can be fragile, failing without warning to end-users. 
- Consequently, checklist questions surrounding a cultural heritage dataset, its provenance, and the digitization pipeline used to produce it are instructive for researchers as they familiarize themselves with the dataset.
- Though datasets have always been essential to the field of machine learning, it has been only in recent years that the discipline has begun to adopt a critical lens toward examining their construction, composition, and utilization. Often motivated in the literature through invocations of examples of machine learning models being deployed in high stakes decision-making processes (i.e., medical diagnosis, legal recidivism, and credit score determination), an emerging body of work is calling for researchers to publish dataset assessments along with the datasets themselves.
- Lyneise Williams has documented how the distortive effects of the microfilming process can lead to erasure of people of color by saturating darker skin tones (Williams, 2019). This phenomenon is present within Chronicling America and digital cultural heritage collections writ large. In particular, the Newspaper Navigator data archaeology demonstrates how embeddings generated by a ResNet model pre-trained on ImageNet fail to retrieve the same photograph of W.E.B. Du Bois among four different digitized Chronicling America newspaper pages due to precisely this effect of microfilming distortion.

- To see collections as data begins with reframing all digital objects as data. Data are defined as ordered
information, stored digitally, that are amenable to computation. Wax cylinders, reel to reel tape, vellum
manuscripts, websites, masterworks, musical scores, social media, code, and software in digital
collections are brought onto the same field of consideration. The value of such a shift can be explored in
part by asking how thinking about an object as data multiplies and/or extends the questions that can be
asked.
- Meaning making with collections as data is not solely a consideration of whether a computer can be used
to process, visualize, and mine them. An orientation to collections as data is about cultivating perception
that pushes past the surface of the things that inhabit digital environments
- To make collections as data usable, the processes by which they are established must be made legible.
These data are the product of design decisions whose purposes are typically not available for a user to
consider. Lack of availability can be traced to a predominant understanding of digital collection use that
does not address the needs of users who desire to work with collections computationally. The result is the
presentation of seamless digital collections that aim to support interactions with objects rather than with
the data that comprise those objects.
- In his talk, Maciej Ceglowski warned against overdependence on algorithmic
approaches to working with data. For certain purposes Ceglowski pointed to the benefits these approaches
could generate for working through digital collections to identify objects in images. Yet he warned
against their potential to become “money laundering for bias” without sustained and nuanced human
intervention. Melissa Parham argued that every act of data collection is an act of erasure – either implied
by what is collected or not collected, or explicit via collection normalization. 


- For the training, fine-tuning, and evaluation of AI methods and models, suitably large-scale
data are a necessary precondition. However, digital and freely reusable datasets of relevant size,
quality and diversity, especially for the historical and culture domain, are still sparse. Here,
digitized cultural heritage can potentially help to fill a current gap. But it is important to ensure
that the cultural heritage collections (and their metadata) that are being digitized are also made
available in the appropriate ways for use in the further development of AI technologies, with
appropriate documentation, and on platforms suitable for this purpose. M
- Another important factor in the provision of digitized cultural heritage for AI research (and
beyond) is the responsible curation of such data. The ongoing documentation, contextualization
and, when necessary, updating and versioning is a desideratum of many datasets currently
widely used in AI research; on the other hand, libraries in particular have the competencies
and established processes for curation and a high level of quality awareness in this regard.
This curation should also extend to include awareness for the identification and appropriate
treatment of problematic content in cultural heritage collections with regard not only to quality
or copyright, but ethical and social biases and issues in the data
- What are the reasons why digitized cultural heritage data has so far only been used in isolated cases in the research and development of AI?
  - Libraries usually publish their digitized collections in online portals for discovery, with the option to search and browse either by metadata or (when available) full-text by keyword search --> But APIs alone are not sufficient. Simple download dumps are often more useful to quickly explore what is being offered, without the need to learn or utilize an API.
  - Libraries typically publish data in formats that are de-facto standards in the digital library world, such as e.g. XML-based family of formats METS3/MODS4/ALTO5, this considerably raises the barrier for reuse of this data in other domains. In contrast, most developers in AI will be more happy to work with formats like CSV or JSON, where numerous software libraries are available to process these further with. 


- How does big data account for contested subjects, which are present in almost every archive?
  - Example: Zealy Daguerreotypes
  - Series of photographs commissioned by naturalist Louis Agassiz in 1850 featuring enslaved men and women as part of his effort to document physical evidence of polygenism.
  - Tamara Lanier, a descendant of two of Agassiz's "subjects", suing Harvard for unlawfully possessing and profiting from the image of her ancestors.


- The conversation grows ever more urgent. Gaps of excess, scarcity, knowability, and representability are being dramatically reconfigured, virtually daily, by digitization projects. This has allowed “culturomics” to spot sweeping trends, but just as—if not more—importantly for historians, it has also given us the tools to create, in Hitchcock’s words, “a more useable history from below made of lives knowable only through small fragments of information” because it allows us to find out so much more information so much more quickly. It means we are able, as Hitchcock puts it, to “radically contextualize” individuals by exploring the multiple archival contexts in which they appear or are represented. Using different kinds of data and more data, we can tell fuller stories about people who have previously been considered lost, virtually unknowable, glimpsed fleetingly, invisible to history.39 [@laite_emmets_2020]
- Whereas we could once attempt to radically contextualize those who had serendipitously left some meaty trace behind, we can now, if we are modernists, do it for a much larger portion of the world’s population.[@laite_emmets_2020]
- We argue that while big data often appear to offer new, shiny, and automated methods that render older archival orders obsolete, big data in fact often repeat—with a difference—the epis- temologies, injustices, and anxieties exemplified by previous archival orders. [@bonde_thylstrup_uncertain_2021, 4]
- In a “postracial” age in which racism has been understood as a moral failing (Goldberg 2009), technology is often seen as ensuring that “human error” does not intervene to reinstall racial division.[@bonde_thylstrup_uncertain_2021, 58]
- Our understandings of data analytics and digital archives often take place through the remediation of earlier forms of data analytics, which tend toward the eradication of uncer- tainty and what exceeds certain normalizing tendencies. As Gitelman and Jackson (2013, 8) argue, these aggregated patterns and their algorithmic supports often obscure “ambiguity, conflict and contradiction,” engaging in acts of erasure in order to associate, connect, and produce what we might identify as collective phenomena (see Blackman 2016).[@bonde_thylstrup_uncertain_2021, 279]

## As Metadata
- One of the signficant purported benefits of using archives as sources of big data is the often substatial metadata associated with archival items; it allows for those using the archive as data to more easily filter for subjects they want to exclude and extract the items they desire for the final dataset through the use of tags or words mentioned in the description. However, what happens when the metadata is not adequately descriptive/does not adequately protect vulnerable histories?
  - The daguerreotypes of Renty, Delia, and the other enslaved men and women photographed by Joseph T. Zealy are present in Harvard's Peabody Museum Collections Online, and in fact, the first of the search results for "daguerreotype": https://collections.peabody.harvard.edu/search/daguerreotype/objects
  - There is no indication of the history associated with these photos in the metadata, no context given about the enslaved subjects or the fact the photographed individuals were enslaved, nor the photos' purpose as "proof" of polygenesis by Agassiz. No indication that these photos were contested at all.
  - These individuals are not safe from being commodified again; as images in the public domain these, they could easily end up in scraped into a dataset and used for the purpose of machine learning/image generation like DALLE.


- Microscopic questions being difficult to answer because the metadata for each archival item used is omitted during the process of data collection
- To produce meaningful output using either analog or automated research methods such as machine learning for identification, it is vital to interrogate the input that contributed to the making of the method



One reason behind the repurposing of the digital archive as Big data that was not mentioned before is metadata enrichment; along with digitization, metadata enrichment plays a crucial role in transforming digital archives into Big Data. Metadata provides descriptive information about the archived content, such as title, author, date, location, and subject. By enhancing the metadata associated with digital archives, researchers and data scientists gain a more comprehensive understanding of the content and can more extensively explore connections and patterns within the data through linking existing metadata [without much effort].

- What gets or does not get digitized and made discoverable through metadata determines what material is available to users—whether general audiences looking for information or researchers seeking material for quantitative textual analysis—exacerbating the omissions of the print cultural record.[@bonde_thylstrup_uncertain_2021, 162]

- Where metadata lacks, the model trained on this data lacks


